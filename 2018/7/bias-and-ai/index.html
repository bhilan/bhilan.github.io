<!doctype html>
<html class="no-js" lang="">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Bias in AI Happens When We Optimize the Wrong Thing</title>
    <meta name="description" content="Bias is a pervasive problem in AI. Only by discouraging machine learning systems from exploiting a certain bias can we expect such a system to avoid doing so.">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    
    

<link rel="apple-touch-icon" sizes="57x57" href="/static/c2c_icons/apple-touch-icon-57x57.png">
<link rel="apple-touch-icon" sizes="60x60" href="/static/c2c_icons/apple-touch-icon-60x60.png">
<link rel="apple-touch-icon" sizes="72x72" href="/static/c2c_icons/apple-touch-icon-72x72.png">
<link rel="apple-touch-icon" sizes="76x76" href="/static/c2c_icons/apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" sizes="114x114" href="/static/c2c_icons/apple-touch-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="/static/c2c_icons/apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" sizes="144x144" href="/static/c2c_icons/apple-touch-icon-144x144.png">
<link rel="apple-touch-icon" sizes="152x152" href="/static/c2c_icons/apple-touch-icon-152x152.png">
<link rel="apple-touch-icon" sizes="180x180" href="/static/c2c_icons/apple-touch-icon-180x180.png">
<link rel="icon" type="image/png" href="/static/c2c_icons/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/static/c2c_icons/favicon-194x194.png" sizes="194x194">
<link rel="icon" type="image/png" href="/static/c2c_icons/favicon-96x96.png" sizes="96x96">
<link rel="icon" type="image/png" href="/static/c2c_icons/android-chrome-192x192.png" sizes="192x192">
<link rel="icon" type="image/png" href="/static/c2c_icons/favicon-16x16.png" sizes="16x16">
<link rel="manifest" href="/static/c2c_icons/manifest.json">
<link rel="mask-icon" href="/static/c2c_icons/safari-pinned-tab.svg" color="#773333">
<link rel="shortcut icon" href="/static/c2c_icons/favicon.ico">
<meta name="msapplication-TileColor" content="#773333">
<meta name="msapplication-TileImage" content="/static/c2c_icons/mstile-144x144.png">
<meta name="msapplication-config" content="/static/c2c_icons/browserconfig.xml">
<meta name="theme-color" content="#ffffff">

    <!-- 3rd March 2022 07:41 -->
    <!-- Fonts -->    
    <link href='https://fonts.googleapis.com/css?family=Unica+One' rel='stylesheet' type='text/css'>
    <script src="https://use.typekit.net/qeu2zlf.js"></script>
    <script>try{Typekit.load({ async: false });}catch(e){}</script>
    <noscript>
      <!-- Fallback fonts (if no JS) -->
      <link href='http://fonts.googleapis.com/css?family=Dosis:400|Anonymous+Pro' rel='stylesheet' type='text/css'>
    </noscript>

    <!-- Styles / Scripts -->
    
    <link rel="stylesheet" href="/static/styles/css/cachestocaches.min.css"/>
    <script src="/static/styles/js/modernizr-2.8.3.min.js"></script>

    

  
  
  
  <meta name="twitter:card"
          content="summary_large_image" />
  <meta prefix="og: http://ogp.me/ns#"
          name="twitter:title"
          property="og:title"
          content="Bias in AI Happens When We Optimize the Wrong Thing" />
  <meta name="twitter:site"
          content="@CachesToCaches">
  <meta prefix="og: http://ogp.me/ns#"
          property="og:type"
          content="website" />
  
  
    <meta prefix="og: http://ogp.me/ns#"
            name="twitter:image:src"
            property="og:image"
            content="http://cachestocaches.com/static/logos/c2c_logo_card_render.jpg" />
  
  
  <meta prefix="og: http://ogp.me/ns#"
          name="twitter:description"
          property="og:description"
          content="Bias is a pervasive problem in AI. Only by discouraging machine learning systems from exploiting a certain bias can we expect such a system to avoid doing so." />
  <meta prefix="og: http://ogp.me/ns#"
          property="og:url"
          content="http://cachestocaches.com/2018/7/bias-and-ai/" />

  </head>

  <body
      itemscope
      itemtype="http://schema.org/WebPage"
      data-spy="scroll"
      data-target="#side-nav">
    
    <nav class="sidebar">
      <div class="content">
        
  <div><a href="/"><img src="/static/logos/c2c_logo_2.png" class="img-responsive center-block" style="width:240px;"/></a></div>
  <br/>
  <div class="center-text narrow-font">
    <span><a href="/">home</a></span>
    <span class="center-dot"></span>
    <span><a href="/archive/">archive</a></span>
    <span class="center-dot"></span>
    <span><a href="/contributors/">about</a></span>
  </div>
  <div class="social-icon-container">
    <a class="social-icon light-border twitter" href="https://twitter.com/intent/follow?screen_name=CachesToCaches"></a>
    <a class="social-icon light-border facebook" href="https://www.facebook.com/CachesToCaches"></a>
    <a class="social-icon light-border googleplus" href="https://www.google.com/+Cachestocaches_c2c" rel="publisher"></a>
    <a class="social-icon light-border github" href="https://github.com/CachesToCaches"></a>
    <a class="social-icon light-border rss-feed" href="/feed"></a>
  </div>

  <img class="bottom-art" src="/static/art/c2c_triangles.svg"></img>
  <div class="center-text floating-description"><a href="http://gjstein.com">designed and maintained by<br/>Gregory J Stein</a></div>

        <br/>
        
  <div class="title"><a href="#">Bias in AI Happens When We Optimize the Wrong Thing</a></div>
  <hr/>
  <div id="nav-sidebar">
    <ul class="nav" id="toc"></ul>
  </div>
  <hr/>
  
    <br/>
    <div class="title">
      <div><small>part 1 of</small></div>
      <a href="/series/ai-perspectives/" class="nav-title">AI Perspectives</a>
    </div>
    <hr/>
    <div class="description">Reflections on the progress, promise, and impact of AI.</div>
    <hr/>
  

      </div>
    </nav>
    <nav class="header">
      
  <div class="content">
  <span class="heading-font"><a href="/">Caches to Caches</a> | </span><span><a href="/">home</a></span><span class="center-dot"></span><span><a href="/archive/">archive</a></span><span class="center-dot"></span><span><a href="/contributors/">about</a></span>
  </div>

    </nav>
    <div class="page"
         itemsope
         itemtype="http://schema.org/Blog">
      <div class="content-top">
        
  <div class="unit-line-height">
  
  <!-- Series Details -->

  <!-- Post Image -->
    <div class="marginnote invisible-sm post-detail">
      <div>
      
        <p><div class="unit-line-height"><small class="heading-font">
          Part 1 of
        </small></div>
        <div><a class="series heading-font" href="/series/ai-perspectives/">AI Perspectives</a></div>
        </p>
      

        <p><div class="date heading-font">Sun 29 Jul 2018</div>
          <a href="/contributors/#gregory-j-stein"><span class="author" itemprop="name">Gregory J Stein</span></a>
          
        </p>

        
          <p><div class="heading-font">Category</div>
            <a class="category" href="/category/machine-learning/">
              Machine Learning
            </a>
          </p>
        

        
          <p><div class="heading-font">Tags</div>
            
              <a class="tag" href="/tag/editorial/">Editorial</a>
            
              <a class="tag" href="/tag/deep-learning/">Deep Learning</a>
            
          </p>
        
      </div>
    </div>

    
      <h1 class="title">
        <div>
          <span itemprop="name">Bias in AI Happens When We Optimize the Wrong Thing</span>
        </div>
      </h1>
    

    


    <div class="note visible-sm post-detail">
      <div>

      <div>
        <span class="date heading-font">Sun 29 Jul 2018</span>
          <a href="/contributors/#gregory-j-stein"><span class="author" itemprop="name">Gregory J Stein</span></a>
          
      </div>

        
          <div>
          <span class="heading-font">Category</span>
            <a class="category" href="/category/machine-learning/">
              Machine Learning
            </a>
          </div>
        

        
          <div><span class="heading-font">Tags</span>
            
              <a class="tag" href="/tag/editorial/">Editorial</a>
            
              <a class="tag" href="/tag/deep-learning/">Deep Learning</a>
            
          </div>
        


        
        <div style="height: 10px"></div>
            <div><span class="unit-line-height"><span class="heading-font">
              Part 1 of
            </span></span>
            <span><a class="series heading-font" href="/series/ai-perspectives/">AI Perspectives</a></span>
            </div>
          
      </div>
    </div>


</div>


      </div>
      <div class="content">
        
  
  <div class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">

  <!-- Post Title -->
  
  

  <!-- Post Content -->
  
    <div class="justify word-break" itemprop="articleBody">
      
        <p>Finding examples of "problematic" AI is relatively easy these days. Microsoft has inadvertently given rise to <a href="https://www.theverge.com/2016/3/24/11297050/tay-microsoft-chatbot-racist">an unhinged, neo-nazi Twitter Bot</a> while an AI beauty contest judge <a href="https://www.theguardian.com/technology/2016/sep/08/artificial-intelligence-beauty-contest-doesnt-like-black-people">seems to strongly favor white women</a>. Despite the sensational nature of these examples, they reflect a pervasive problem plaguing many modern AI systems.</p>
<p>Machine learning is designed to discover and exploit patterns in data so as to optimize some notion of performance. Most measures of <em>good performance</em> involve maximizing accuracy, yet this performance metric is often sufficient only for situations in which perfect accuracy can be achieved<span class="sidenote note no-word-break invisible-sm">The notion of "perfect accuracy" is also simplistic in general. If an AI system is being used to screen candidates to hire, deciding how to define accuracy is already a value judgment. </span>. When a task is difficult enough that the system is prone to errors, AI agents may fail in ways that we, as humans, may consider unfair or that take advantage of undesirable patterns in the data. Here, I discuss the issue of bias in AI and argue that great care must be taken to train a machine learning system to avoid systematic bias.
<p class="note no-word-break visible-sm">The notion of "perfect accuracy" is also simplistic in general. If an AI system is being used to screen candidates to hire, deciding how to define accuracy is already a value judgment. </p></p>
<blockquote>
In short, if you are a business professional looking to use some form of machine learning, you need to be aware of how bias can manifest itself in practice.
</blockquote>

<p></p>
<p>I define bias more broadly than many colloquial definitions so that it captures the more subtle effects that can appear in machine learning contexts: bias is when a machine learning system treats a some distinguishable subgroup of the data in an undesirable way. Among the more well-known examples are machine learning tools that exhibit social biases present in the data used to train them. For instance, <a href="https://arxiv.org/pdf/1607.06520.pdf">one popular machine learning technique</a> designed to work with natural language infamously associated the word "woman" with gender-stereotypical vocations like "receptionist" and "homemaker"<span class="sidenote note no-word-break invisible-sm">For more detailed perspective on how social biases manifest themselves in AI systems, I recommend reading <a href="https://www.whitecase.com/publications/insight/algorithms-and-bias-what-lenders-need-know">this article</a> from Kevin Petrasic and Benjamin Saul of the law firm White &amp; Case. </span>.
<p class="note no-word-break visible-sm">For more detailed perspective on how social biases manifest themselves in AI systems, I recommend reading <a href="https://www.whitecase.com/publications/insight/algorithms-and-bias-what-lenders-need-know">this article</a> from Kevin Petrasic and Benjamin Saul of the law firm White &amp; Case. </p></p>
<p>Yet machine learning bias is not exclusively a byproduct of "prejudiced" data. For example, consider a training dataset with 1,000 images: 990 contain cats and the remaining 10 contain dogs. A typical machine learning task on such a dataset is classification, automatically determining if a new image contains either a cat or a dog. Most standard machine learning classifiers aim to maximize performance on the training dataset, yet problems arise because of the large imbalance in the number of images of cats and dogs in the data fed to the algorithm. The machine learning algorithm can easily achieve 99% accuracy on the training dataset by simply predicting that every image contains a cat. Since the resulting system systematically misclassifies all images of dogs, we may reasonably say that the system is <em>unfair</em> or <em>biased</em>.</p>
<p>Though the cat/dog classifier is rather innocuous, imagine instead a system that is supposed to locate people in an image as part of a self-driving car AI. Perhaps the training data contains more men than women, and suddenly the autonomous vehicle is more likely to collide with female pedestrians. Similarly, an automated resume screening system may strongly prefer hiring white men over otherwise equal candidates. These examples are almost trivially clear-cut: it is obvious that these systems are biased in a way that we consider problematic. Unfortunately, discovering hidden biases can be difficult. This is especially true of machine learning systems for which decision making may be opaque, so that the correlations they discover between different features of the data are almost impossible to probe.</p>
<p>Only by discouraging machine learning systems from exploiting a certain bias can we expect such a system to avoid doing so. Relatedly, most of the objectives used in modern machine learning fail to take into account human judgment, resulting in AI systems that fail to capture notions of human values like fairness. How a machine should weigh the relative importance of <em>accuracy</em> and <em>fairness</em> is an area of active research. Yet a general function capable of evaluating the fairness of a machine learning system across arbitrary application domains remains an elusive goal, and so <em>algorithmic implementations of fairness</em> are uncommon in off-the-shelf machine learning tools.<span class="sidenote note no-word-break invisible-sm">Though machine learning tools are not yet "bias aware" by default, it is worth mentioning that many recent companies looking to provide machine-learning-based services are <a href="https://www.americanbanker.com/news/can-ai-be-programmed-to-make-fair-lending-decisions">actively including mechanisms to fight bias</a>. </span>
<p class="note no-word-break visible-sm">Though machine learning tools are not yet "bias aware" by default, it is worth mentioning that many recent companies looking to provide machine-learning-based services are <a href="https://www.americanbanker.com/news/can-ai-be-programmed-to-make-fair-lending-decisions">actively including mechanisms to fight bias</a>. </p></p>
<p>With the ever-lengthening list of tasks that modern machine learning has be used to automate, it is often easy to overlook the potential problems such systems can introduce. Understanding how these systems can exacerbate problems in the datasets they are trained on is the first step towards addressing the issue. As machine learning tools are put into production, it is ultimately the responsibility of their designers to ensure that such systems do not exploit unintended bias.</p>
      
    </div>
  

  <!-- Post Footer -->
  

  <!-- Additional Metadata -->
  <meta itemprop="description" content="Bias is a pervasive problem in AI. Only by discouraging machine learning systems from exploiting a certain bias can we expect such a system to avoid doing so.">

</div>


      </div>
      <div class="content-bottom">
        

  <hr/>
  <p><blockquote>
    Liked this post? Subscribe to our <a class="post-link" href="/feed">RSS feed</a> or add your email to our newsletter:

    <!-- Begin MailChimp Signup Form -->
    <link href="//cdn-images.mailchimp.com/embedcode/horizontal-slim-10_7.css" rel="stylesheet" type="text/css">
    <div id="mc_embed_signup">
      <form action="https://cachestocaches.us15.list-manage.com/subscribe/post?u=f290745e370ad37f53ed7c7ac&amp;id=b7922d14de" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
        <div id="mc_embed_signup_scroll">
	  
	  <input type="email" value="" name="EMAIL" class="email" id="mce-EMAIL" placeholder="email address" required>
          <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
          <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_f290745e370ad37f53ed7c7ac_b7922d14de" tabindex="-1" value=""></div>
          <div class="clear"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
        </div>
      </form>
    </div>

  </blockquote></p>

  <!--End mc_embed_signup-->
  <hr/>


  <!-- All posts in series -->
  
    <div class="post-list">
      <div class="heading-font">all posts in series</div>
      <h3><a href="/series/ai-perspectives/" class="nav-title">AI Perspectives</a></h3>
      <div class="small-line-height">Reflections on the progress, promise, and impact of AI.</div>
      <ul class="small-post-list">
        
          <li class="selected"><a class="small-title" href="/2018/7/bias-and-ai/">1 <span class="center-dot"></span> Bias in AI Happens When We Optimize the Wrong Thing</a>
            <div class="small-detail">Bias is a pervasive problem in AI. Only by discouraging machine learning systems from exploiting a certain bias can we expect such a system to avoid doing so.</div></li>
        
          <li ><a class="small-title" href="/2018/9/ai-translation-more-language/">2 <span class="center-dot"></span> For AI, translation is about more than language</a>
            <div class="small-detail">Translation is about expressing the same underlying information in different ways, and modern machine learning is making incredibly rapid progress in this space.</div></li>
        
          <li ><a class="small-title" href="/2018/9/guidelines-practical-ai/">3 <span class="center-dot"></span> Practical Guidelines for Getting Started with Machine Learning</a>
            <div class="small-detail">The potential advantages of AI are many, and using machine learning to accelerate your business may outweigh potential pitfalls. If you are looking to use machine learning tools, here are a few guidelines you should keep in mind.</div></li>
        
          <li ><a class="small-title" href="/2018/12/toward-real-world-alphazero/">4 <span class="center-dot"></span> DeepMind&#x27;s AlphaZero and The Real World</a>
            <div class="small-detail">Using DeepMind&#x27;s AlphaZero AI to solve real problems will require a change in the way computers represent and think about the world. In this post, we discuss how abstract models of the world can be used for better AI decision making and discuss recent work of ours that proposes such a model for the task of navigation.</div></li>
        
          <li ><a class="small-title" href="/2019/1/staggering-amounts-data/">5 <span class="center-dot"></span> Massive Datasets and Generalization in ML</a>
            <div class="small-detail">Big, publically available datasets are great. Yet many practitioners who seek to use models pretrained on this data need to ask themselves how informative the data is likely to be for their purposes. Dataset bias and task specificity are important factors to keep in mind.</div></li>
        
          <li ><a class="small-title" href="/2019/1/proxy-metrics-are-everywhere-machine-lea/">6 <span class="center-dot"></span> Proxy metrics are everywhere in Machine Learning</a>
            <div class="small-detail">Many machine learning systems are optimized using metrics that don&#x27;t perfectly match the stated goals of the system. These so-called &quot;proxy metrics&quot; are incredibly useful, but must be used with caution.</div></li>
        
          <li ><a class="small-title" href="/2019/5/neural-network-structure-and-no-free-lun/">7 <span class="center-dot"></span> No Free Lunch and Neural Network Architecture</a>
            <div class="small-detail">Machine learning must always balance flexibility and prior assumptions about the data. In neural networks, the network architecture codifies these prior assumptions, yet the precise relationship between them is opaque. Deep learning solutions are therefore difficult to build without a lot of trial and error, and neural nets are far from an out-of-the-box solution for most applications.</div></li>
        
          <li ><a class="small-title" href="/2019/8/efficiency-artificial-neural-networks-ve/">8 <span class="center-dot"></span> On the efficiency of Artificial Neural Networks versus the Brain</a>
            <div class="small-detail">Recent ire from the media has focused on the high-power consumption of artificial neural nets (ANNs), yet popular discussion frequently conflates training and testing. Here, I aim to clarify the ways in which conversations involving the relative efficiency of ANNs and the human brain often miss the mark.</div></li>
        
          <li ><a class="small-title" href="/2019/12/my-state-of-the-field/">9 <span class="center-dot"></span> Machine Learning &amp; Robotics: My (biased) 2019 State of the Field</a>
            <div class="small-detail">My thoughts on the past year of progress in Robotics and Machine Learning.</div></li>
        
          <li ><a class="small-title" href="/2020/3/valley-of-ai-trust/">10 <span class="center-dot"></span> The Valley of AI Trust</a>
            <div class="small-detail">Particularly for safety-critical applications or the automation of tasks that can directly impact quality of life, we must be careful to avoid the valley of AI trustâ€”the dip in overall safety caused by premature adoption of automation.</div></li>
        
      </ul>
    </div>
    <hr/>
  

  <div>
  <div class="social-icon-container visible-xs">
    <a class="social-icon twitter"
         href="https://twitter.com/intent/tweet?url=http%3A%2F%2Fcachestocaches.com%2F2018%2F7%2Fbias-and-ai%2F&text=Great%20post%20at"></a><a class="social-icon facebook"
         href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Fcachestocaches.com%2F2018%2F7%2Fbias-and-ai%2F"></a><a class="social-icon googleplus"
         href="https://plus.google.com/share?url=http%3A%2F%2Fcachestocaches.com%2F2018%2F7%2Fbias-and-ai%2F"></a><a class="social-icon linkedin"
         href="http://www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Fcachestocaches.com%2F2018%2F7%2Fbias-and-ai%2F&title=Caches%20To%20Caches&source=http%3A//cachestocaches.com"></a><a class="social-icon rss-feed"
         href="/feed"></a>
  </div>
</div>


  <hr/>

  <script type="text/javascript">
/* * * CONFIGURATION VARIABLES * * */
var disqus_shortname = 'cachestocaches';

/* * * DON'T EDIT BELOW THIS LINE * * */
 function createCallback() {
     var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
     dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
     (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
   };
</script>
<a class="heading-font" id="disqus_thread" style="cursor:pointer;"onclick="createCallback();return false;"><h4 class="constrain-width">+ Show Comments From Disqus</h4></a>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

  

      </div>
    </div>

    <!-- Footer -->
    <div class="footer">
      <div class="content">
      
  <div><a href="/"><img src="/static/logos/c2c_logo_2.png" class="img-responsive center-block" style="width:240px;"/></a></div>
  <br/>
  <div class="center-text narrow-font">
    <span><a href="/">home</a></span>
    <span class="center-dot"></span>
    <span><a href="/archive/">archive</a></span>
    <span class="center-dot"></span>
    <span><a href="/contributors/">about</a></span>
  </div>
  <div class="social-icon-container">
    <a class="social-icon light-border twitter" href="https://twitter.com/intent/follow?screen_name=CachesToCaches"></a>
    <a class="social-icon light-border facebook" href="https://www.facebook.com/CachesToCaches"></a>
    <a class="social-icon light-border googleplus" href="https://www.google.com/+Cachestocaches_c2c" rel="publisher"></a>
    <a class="social-icon light-border github" href="https://github.com/CachesToCaches"></a>
    <a class="social-icon light-border rss-feed" href="/feed"></a>
  </div>

  <br/>
  <div class="center-text"><a href="http://gjstein.com">designed and maintained by<br/>Gregory J Stein</a></div>

      
      
      </div>
    </div>

    <!-- Scripts -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>

    <!-- Sidebar / Table of Contents -->
    <script src="/static/styles/js/jquery.tableofcontents.g.min.js"></script>
    <script src="/static/styles/js/sticky-nav.js"></script>
    <script src="/static/styles/js/bootstrap-scrollspy.min.js"></script>
    <script>
    $(function(){$("#toc").tableOfContents(null,{
      startLevel: 2, depth: 1});
      $('body').scrollspy({
        target: '#nav-sidebar',
        offset: 20});
    });
    </script>
    
    <!-- Code Highlighting : highlight.js -->
    

<!-- <link rel="stylesheet" href="/static/highlight/styles/c2c.css"> -->
<script src="/static/highlight/highlight.pack.js"></script>
<script>hljs.configure({languages:[]});hljs.initHighlightingOnLoad();</script>
<script src="/static/styles/js/anchor-scroll.js"></script>


    <!-- Equation Rendering : mathjax -->
    <script type="text/x-mathjax-config">
     MathJax.Hub.Config({
       jax: ["input/TeX","output/CommonHTML"],
       tex2jax: { inlineMath: [["$","$"]] },
       CommonHTML: {
         linebreaks: { automatic: true, width: "container" }
       }
     });
    </script>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML" type="text/javascript"></script>

    
  <script>
  (function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=
          function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;
          e=o.createElement(i);r=o.getElementsByTagName(i)[0];
          e.src='//www.google-analytics.com/analytics.js';
          r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));
  ga('create','UA-60578350-2','auto');ga('send','pageview');
  </script>

  </body>
</html>
